以下是关于视觉第二次培训后作业的一些记录。
首先是opencv的下载与环境搭建。按照旧例，我前往csdn对“Ubuntu，opencv，c++”等关键词进行检索，并随之打开一篇教程文档进行安装和配置。不幸的是，在第二步我就停下了脚步，原因是“无法检索到cmakelists.txt”，在求助智能体无果后，我开始了具有一定持续时长的沉默和冥想。重新开始审视每一步时，我很遗憾地发现我还没有去官网下载opencv的zip安装包就在命令行进行了安装操作，在下载后这个问题也是得到了较为妥善的解决。
之后，建立对应的文件和文件夹，但在运行main.cpp时发现出现了file not found的问题。在json文件中添加了对应的路径后，问题仍没有得到解决。后面发现还没有安装ninga构建工具，安装完成后重新运行，仍然报错。重新构建文件后，在json中添加了根目录，依旧显示报错。尝试调整tasks.json，加入了相应的路径代码，依然报错。在三次重新添加路径后，报错的内容不再是file not found，变成了“无法读取图像”。仔细研读代码后，发现问题在于读取文件时把.png写成了.jpg，在解决这个问题后代码也是成功得到了运行。
在opencv基础使用模块中，提取高亮区域使用了灰度大于200作为高亮的指标，同时，将膨胀和腐蚀合并为一张“膨胀后腐蚀”的闭运算作为输出结果。另外，在“图像绘制”中，把红色区域轮廓图和bounding box的输出都放在了先前提取红色颜色区域部分。
接下来是实际应用模块。发现一般的代码并不能准确地识别出装甲区域，而是连带着找出了许多无关高亮色带。检索网上的识别思路，并对代码做进一步优化，发现识别出来0个装甲板，证明筛选条件过于严苛也不利于结果的正确的识别。放宽搜索条件后，经过多次修改，识别结果大致分为两类，第一种是无法识别出任何装甲板，第二种是识别出了不是装甲板的区域。再继续完善代码后，输出结果依然是0，后面开始调整参数。调整参数后，识别到的灯带数量增多了，但是都不是真正的灯带，而是一些无关紧要的外部区域，同时，识别出的装甲板数量也是0。经验证后发现，问题出在通道相减后灯条变成了纯黑色，识别的却是白色的，导致了结果的错误。所以采取反相处理的策略，并加以阈值化限制背景颜色防止误判，通过多次参数调整，发现将阈值定在180-235可以成功识别装甲板区域，但是在阈值较高时可能导致装甲板区域较窄或重叠区域较多，最终选择效果较好的183作为设定值，得到灯带识别的二值图。做反相处理后，在得到的反相图上寻找装甲板的轮廓，最终得到结果。
作业保存与上传环节中，考虑到直接对输出结果截图可能会在视觉观感以外的其他作业验收形式中产生问题，所以在代码中加入将图片保存本地的操作，得到输出结果的原图。但是，不幸的是，经过反复调试，这种保存方式导致不管保存了多少次结果都是原图，几经辗转无果后，遂决定使用屏幕截图的方式保存结果，希望不会出太大的问题。完成结果保存后，接下来就是上传至GitHub。
至此，完成了Task02的内容。
